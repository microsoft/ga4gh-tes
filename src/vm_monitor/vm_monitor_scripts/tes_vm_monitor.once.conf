# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "1s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = false  ## False for once to ensure collection happens once

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  ## Exceeding this value triggers a flush
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "120s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "5s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = "10ms"

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true

# Add a 'once' tag to everything logged by this config (this helps distinguish between once and continuous monitoring)
[global_tags]
  vm_monitor_collection = "once"


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

[[outputs.azure_append_blob]]
  output_path = "${PERF_APPEND_BLOB_PATH}"
  storage_account_name = "${PERF_STORAGE_ACCOUNT_NAME}"
  container_name = "${PERF_CONTAINER_NAME}"
  use_batch_format = true
  data_format = "json"
  json_timestamp_units = "1ms"
  compression_algorithm = "zstd"
  compression_level = 7 ## Attempt to compress verbose 'once' data more

# Send telegraf metrics to stdout (only on for the once config)
[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  files = ["stdout"]
  ## Use batch serialization format instead of line based delimiting.  The
  ## batch format allows for the production of non line based output formats and
  ## may more efficiently encode and write metrics.
  use_batch_format = true
  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  rotation_max_size = "50MB"
  ## Data format to output.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  ## https://github.com/influxdata/telegraf/tree/master/plugins/serializers/json
  data_format = "influx"


###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Capture the output of mount of real /dev devices
# Intent is to ignore all cgroups, etc.
[[inputs.exec]]
  commands = ["/bin/bash -c 'mount | grep ^/dev'"]
  timeout = "5s"
  data_format = "grok"
  grok_patterns = ["^%{UNIXPATH:device} on %{UNIXPATH:mount} type %{WORD:fstype} \\(%{GREEDYDATA:options}\\)"]
  name_override = "exec.mount"
[[inputs.exec]]
  commands = ["/bin/bash -c 'df -T  --exclude-type=squashfs | tail -n +2'"]
  timeout = "5s"
  data_format = "grok"
  grok_patterns = ["^%{NOTSPACE:filesystem}\\s+%{NOTSPACE:type}\\s+%{NUMBER:1K-blocks:int}\\s+%{NUMBER:used:int}\\s+%{NUMBER:available:int}\\s+%{NUMBER:use_percent:int}%\\s+%{GREEDYDATA:mounted_on}"]
  name_override = "exec.df"
[[inputs.exec]]
  commands = ["/bin/bash -c 'lsblk -P -b -o NAME,SIZE,MAJ:MIN,FSTYPE,MOUNTPOINT,PTTYPE,MODEL,STATE,TYPE | tail -n +2'"]
  timeout = "5s"
  data_format = "grok"
  grok_patterns = ["^NAME=\"%{NOTSPACE:name}\" SIZE=\"%{NUMBER:size:int}\" MAJ:MIN=\"%{DATA:maj_min}\" FSTYPE=\"%{DATA:fstype}\" MOUNTPOINT=\"%{DATA:mountpoint}\" PTTYPE=\"%{DATA:pttype}\" MODEL=\"%{DATA:model}\" STATE=\"%{DATA:state}\" TYPE=\"%{DATA:type}\""]
  name_override = "exec.lsblk"
[[inputs.exec]]
  commands = ["/bin/bash -c 'env | grep -v -E \"^BASH_FUNC_|^LS_COLORS\"'"]
  timeout = "5s"
  data_format = "grok"
  grok_patterns = ["^%{NOTSPACE:key}=%{GREEDYDATA:value}"]
  name_override = "exec.env"

[[inputs.exec]]
  ## Commands array
  commands = [
    "/bin/bash ${PERF_SCRIPT_DIR}/collect_azure_vm_perf.sh ${PERF_SCRIPT_DIR}/"
  ]
  ## Timeout for each command to complete.
  timeout = "5s"
  ## Data format to consume.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "influx"
[[inputs.exec]]
  commands = [
    "/bin/sh -c 'echo task_env,tag=VM_TASK_NAME value=\"\\\"${VM_TASK_NAME}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=TASK_WORKING_DIR value=\"\\\"${TASK_WORKING_DIR}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=PERF_SCRIPT_DIR value=\"\\\"${PERF_SCRIPT_DIR}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=ONE_TIME_CONFIG_CLEAN value=\"\\\"${ONE_TIME_CONFIG_CLEAN}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=CONTINUOUS_CONFIG_CLEAN value=\"\\\"${CONTINUOUS_CONFIG_CLEAN}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=PERF_APPEND_BLOB_PATH value=\"\\\"${PERF_APPEND_BLOB_PATH}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=PERF_STORAGE_ACCOUNT_NAME value=\"\\\"${PERF_STORAGE_ACCOUNT_NAME}\\\"\"'",
    "/bin/sh -c 'echo task_env,tag=PERF_CONTAINER_NAME value=\"\\\"${PERF_CONTAINER_NAME}\\\"\"'"
  ]
  timeout = "5s"
  # name_suffix = "task_env"
  data_format = "influx"
[[inputs.file]]
  ## Files to parse each interval.  Accept standard unix glob matching rules,
  ## as well as ** to match recursive files and directories.
  files = ["${PERF_SCRIPT_DIR}/tes_vm_monitor.once.clean.conf"]
  name_override = "telegraf_config_once"
  data_format = "value" # Name of the field (e.g. "value=")
  data_type = "string"
  character_encoding = "utf-8"
[[inputs.file]]
  ## Files to parse each interval.  Accept standard unix glob matching rules,
  ## as well as ** to match recursive files and directories.
  files = ["${PERF_SCRIPT_DIR}/tes_vm_monitor.continuous.clean.conf"]
  name_override = "telegraf_config_continuous"
  data_format = "value" # Name of the field (e.g. "value=")
  data_type = "string"
  character_encoding = "utf-8"

# Take a quick snapshot of the /mnt state:
[[inputs.filecount]]
  ## Directories to gather stats about.
  ## This accept standard unit glob matching rules, but with the addition of
  ## ** as a "super asterisk". ie:
  ##   /var/log/**    -> recursively find all directories in /var/log and count files in each directories
  ##   /var/log/*/*   -> find all directories with a parent dir in /var/log and count files in each directories
  ##   /var/log       -> count all files in /var/log and all of its subdirectories
  directories = ["/mnt/**"]
  ## Only count files that match the name pattern. Defaults to "*".
  name = "*"
  ## Count files in subdirectories. Defaults to true.
  recursive = true
  ## Only count regular files. Defaults to true.
  regular_only = true
  ## Follow all symlinks while walking the directory tree. Defaults to false.
  follow_symlinks = false
  ## Only count files that are at least this size. If size is
  ## a negative number, only count files that are smaller than the
  ## absolute value of size. Acceptable units are B, KiB, MiB, KB, ...
  ## Without quotes and units, interpreted as size in bytes.
  size = "0B"
  ## Only count files that have not been touched for at least this
  ## duration. If mtime is negative, only count files that have been
  ## touched in this duration. Defaults to "0s".
  mtime = "0s"

# Collect files stats on files inside the task working directory
[[inputs.filestat]]
  # The timeout means that jobs with hundreds of thousands of files may not collect all information
  files = ["${TASK_WORKING_DIR}/**"]
  md5 = false
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  report_active = false
# Not supported on Azure VMs
# # Provides Linux CPU metrics
# # This plugin ONLY supports Linux
# [[inputs.linux_cpu]]
#   ## Path for sysfs filesystem.
#   ## See https://www.kernel.org/doc/Documentation/filesystems/sysfs.txt
#   ## Defaults:
#   # host_sys = "/sys"
#   ## CPU metrics collected by the plugin.
#   ## Supported options:
#   ## "cpufreq", "thermal"
#   ## Defaults:
#   metrics = ["cpufreq", "thermal"]
[[inputs.disk]]
  interval="30s"
  collection_jitter="5s"
  ## By default stats will be gathered for all mount points.
  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "sysfs", "cgroup", "cgroup2", "devfs", "iso9660", "overlay", "aufs", "squashfs", "vfat"]
[[inputs.diskio]]
  interval="5s"
  collection_jitter="1s"
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  devices = ["sd*", "nvme*"]
  ## On systems which support it, device metadata can be added in the form of
  ## tags.
  device_tags = ["ID_FS_TYPE", "ID_FS_LABEL"]
[[inputs.mem]]
  # no configuration
[[inputs.net]]
  ## On linux systems telegraf also collects protocol stats.
  ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
  ignore_protocol_stats = true
[[inputs.processes]]
  interval="60s"
  collection_jitter="5s"
[[inputs.swap]]
  interval="60s"
  collection_jitter="5s"
  # no configuration
[[inputs.system]]
  interval="60s"
  collection_jitter="5s"
  fieldexclude = ["uptime_format"]  # uptime_format is deprecated
# Read metrics about docker containers
[[inputs.docker]]
  interval="60s"
  ## Docker Endpoint
  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
  endpoint = "unix:///var/run/docker.sock"
  ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)
  ## Note: configure this in one of the manager nodes in a Swarm cluster.
  ## configuring in multiple Swarm managers results in duplication of metrics.
  gather_services = false
  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars
  source_tag = false
  ## Containers to include and exclude. Collect all if empty. Globs accepted.
  container_name_include = []
  container_name_exclude = []
  ## Timeout for docker list, info, and stats commands
  timeout = "5s"
  ## Whether to report for each container per-device blkio (8:0, 8:1...),
  ## network (eth0, eth1, ...) and cpu (cpu0, cpu1, ...) stats or not.
  ## Usage of this setting is discouraged since it will be deprecated in favor of 'perdevice_include'.
  ## Default value is 'true' for backwards compatibility, please set it to 'false' so that 'perdevice_include' setting
  ## is honored.
  perdevice = false
  ## Specifies for which classes a per-device metric should be issued
  ## Possible values are 'cpu' (cpu0, cpu1, ...), 'blkio' (8:0, 8:1, ...) and 'network' (eth0, eth1, ...)
  ## Please note that this setting has no effect if 'perdevice' is set to 'true'
  # perdevice_include = ["cpu", "blkio", "network"]
  perdevice_include = ["blkio", "network"]
  ## Whether to report for each container total blkio and network stats or not.
  ## Usage of this setting is discouraged since it will be deprecated in favor of 'total_include'.
  ## Default value is 'false' for backwards compatibility, please set it to 'true' so that 'total_include' setting
  ## is honored.
  total = false
  ## Specifies for which classes a total metric should be issued. Total is an aggregated of the 'perdevice' values.
  ## Possible values are 'cpu', 'blkio' and 'network'
  ## Total 'cpu' is reported directly by Docker daemon, and 'network' and 'blkio' totals are aggregated by this plugin.
  ## Please note that this setting has no effect if 'total' is set to 'false'
  # total_include = ["cpu", "blkio", "network"]
  ## docker labels to include and exclude as tags.  Globs accepted.
  ## Note that an empty array for both will include all labels as tags
  docker_label_include = []
  docker_label_exclude = []
  ## Which environment variables should we use as a tag
  tag_env = ["JAVA_HOME", "HEAP_SIZE"]

[[inputs.docker_log]]
  interval="60s"
  ## Docker Endpoint
  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
  endpoint = "unix:///var/run/docker.sock"
  ## When true, container logs are read from the beginning; otherwise
  ## reading begins at the end of the log.
  from_beginning = false
  ## Timeout for Docker API calls.
  timeout = "5s"
  ## Containers to include and exclude. Globs accepted.
  ## Note that an empty array for both will include all containers
  container_name_include = []
  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars
  source_tag = false
